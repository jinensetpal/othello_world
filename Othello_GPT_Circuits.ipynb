{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "<b style=\"color: red\">To use this notebook, go to Runtime > Change Runtime Type and select GPU as the hardware accelerator.</b>\n",
    "\n",
    "This is code to accompany my blog post building on Kenneth Li et al's paper Emergent World Representations. I found that the network actually learns a **linear** world model, but in terms of whether a cell contains a piece of **my colour** vs the **opponent's colour**. I demonstrate how to use and intervene with the linear probe I found, use the probe to start interpreting the model and studying circuits, and some starter code for neuron interpretability and activation patching\n",
    "\n",
    "If you're new to mechanistic interpretability, check out [my blog post on getting started](https://neelnanda.io/getting-started). This notebook heavily uses my TransformerLens library, check out [the main tutorial for a better introduction](https://neelnanda.io/transformer-lens-demo).\n",
    "\n",
    "Read the blog post here: https://neelnanda.io/othello\n",
    "\n",
    "Look up unfamiliar terms here: https://neelnanda.io/glossary \n",
    "\n",
    "The paper: https://arxiv.org/pdf/2210.13382.pdf\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Setup (Don't Read This)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running as a Jupyter notebook - intended for development only!\n",
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_123612/347264739.py:21: DeprecationWarning: `magic(...)` is deprecated since IPython 0.13 (warning added in 8.1), use run_line_magic(magic_name, parameter_s).\n",
      "  ipython.magic(\"load_ext autoreload\")\n",
      "/tmp/ipykernel_123612/347264739.py:22: DeprecationWarning: `magic(...)` is deprecated since IPython 0.13 (warning added in 8.1), use run_line_magic(magic_name, parameter_s).\n",
      "  ipython.magic(\"autoreload 2\")\n"
     ]
    }
   ],
   "source": [
    "# Janky code to do different setup when run in a Colab notebook vs VSCode\n",
    "DEVELOPMENT_MODE = False\n",
    "try:\n",
    "    import google.colab\n",
    "    IN_COLAB = True\n",
    "    print(\"Running as a Colab notebook\")\n",
    "    %pip install transformer_lens==1.2.1\n",
    "    %pip install git+https://github.com/neelnanda-io/neel-plotly\n",
    "    \n",
    "    # PySvelte is an unmaintained visualization library, use it as a backup if circuitsvis isn't working\n",
    "    # # Install another version of node that makes PySvelte work way faster\n",
    "    # !curl -fsSL https://deb.nodesource.com/setup_16.x | sudo -E bash -; sudo apt-get install -y nodejs\n",
    "    # %pip install git+https://github.com/neelnanda-io/PySvelte.git\n",
    "except:\n",
    "    IN_COLAB = False\n",
    "    print(\"Running as a Jupyter notebook - intended for development only!\")\n",
    "    from IPython import get_ipython\n",
    "\n",
    "    ipython = get_ipython()\n",
    "    # Code to automatically update the HookedTransformer code as its edited without restarting the kernel\n",
    "    ipython.magic(\"load_ext autoreload\")\n",
    "    ipython.magic(\"autoreload 2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using renderer: colab\n"
     ]
    }
   ],
   "source": [
    "# Plotly needs a different renderer for VSCode/Notebooks vs Colab argh\n",
    "import plotly.io as pio\n",
    "if IN_COLAB or not DEVELOPMENT_MODE:\n",
    "    pio.renderers.default = \"colab\"\n",
    "else:\n",
    "    pio.renderers.default = \"notebook_connected\"\n",
    "print(f\"Using renderer: {pio.renderers.default}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import stuff\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import einops\n",
    "from fancy_einsum import einsum\n",
    "import tqdm.auto as tqdm\n",
    "import random\n",
    "from pathlib import Path\n",
    "import plotly.express as px\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from typing import List, Union, Optional\n",
    "from functools import partial\n",
    "import copy\n",
    "\n",
    "import itertools\n",
    "from transformers import AutoModelForCausalLM, AutoConfig, AutoTokenizer\n",
    "import dataclasses\n",
    "import datasets\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformer_lens\n",
    "import transformer_lens.utils as utils\n",
    "from transformer_lens.hook_points import (\n",
    "    HookedRootModule,\n",
    "    HookPoint,\n",
    ")  # Hooking utilities\n",
    "from transformer_lens import HookedTransformer, HookedTransformerConfig, FactoredMatrix, ActivationCache"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We turn automatic differentiation off, to save GPU memory, as this notebook focuses on model inference not model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.autograd.grad_mode.set_grad_enabled at 0x2b863c21fc10>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.set_grad_enabled(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting helper functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neel_plotly import line, scatter, imshow, histogram"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Othello GPT"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>I was in a massive rush when I made this codebase, so it's a bit of a mess, sorry! This Colab is an attempt to put a smiley face on the underlying shoggoth, but if you want more of the guts, here's an info dump</summary>\n",
    "\n",
    "This codebase is a bit of a mess! This colab is an attempt to be a pretty mask on top of the shoggoth, but if it helps, here's an info dump I wrote for someone about interpreting this codebase:\n",
    "\n",
    "Technical details:\n",
    "\n",
    "-   Games are 60 moves, but the model can only take in 59. It's trained to predict the next move, so they give it the first 59 moves (0<=...<59) and evaluate the predictions for each next move (1<=...<60). There is no Beginning of Sequence token, and the model never tries to predict the first move of the game\n",
    "\n",
    "-   This means that, while in Othello black plays first, here white plays \"first\" because first is actually second\n",
    "\n",
    "-   You can get code to load the synthetic model (ie trained to play uniformly random legal moves) into TransformerLens here: [https://colab.research.google.com/github/neelnanda-io/TransformerLens/blob/main/demos/Othello\\_GPT.ipynb](https://colab.research.google.com/github/neelnanda-io/TransformerLens/blob/main/demos/Othello_GPT.ipynb) \n",
    "-   You can load in their synthetically generated games [from their Github](https://github.com/likenneth/othello_world) (there's a google drive link)\n",
    "-   Their model has 8 layers, residual stream width 512, 8 heads per layer and 2048 neurons per layer.\n",
    "\n",
    "-   The vocab size is 61. 0 is -100, which I *think *means pass, I just filtered out the rare games that include that move and ignore it. 1 to 60 (inclusive) means the board moves in lexicographic order (A0, A1, ..., A7, B0, ...) but *skipping *D3, D4, E3 and E4. These are at the center of the board and so can never be played, because Othello starts with them filled)\n",
    "\n",
    "-   There's 3 ways to denote a board cell. I call them \"int\", \"string\" and \"label\" (which is terrible notation, sorry). \n",
    "\n",
    "-   \"label\" means the label for a board cell, \\[\"A0\", ..., \"A7\", ''', \"H7\"\\] (I index at 0 not 1, sorry!). \n",
    "-   \"int\" means \"part of the model vocabulary\", so 1 means A0, we then count up but miss the center squares, so 27 is D2, 28 is D5, 33 is E2 and 34 is E5. \n",
    "-   \"string\" means \"the input format of the OthelloBoardState class\". These are integers (sorry!) from 0 to 63, and exactly correspond to labels A0, ..., H7, without skipping any center cells. OthelloBoardState is a class in data/othello.py that can play the Othello game and tell you the board state and valid moves (created by the authors, not me)\n",
    "-   I have utility functions to\\_int, to\\_string, str\\_to\\_label and int\\_to\\_label in tl\\_othello\\_utils.py to do this\n",
    "\n",
    "-   The embedding and unembedding are untied (ie, in contrast to most language models, the map W\\_U from final residual to the logits is *not *the transpose of W\\_E, the map from tokens to the initial residual. They're unrelated matrices)\n",
    "-   tl\\_othello\\_utils.py is my utils file, with various functions to load games, etc. \\`board\\_seqs\\_string\\` and \\`board\\_seqs\\_int\\` are massive saved tensors with every move across all 4.5M synthetic games in both string and int format, these are 2.3GB so I haven't attached them lol. You can recreate them from the synthetic games they provide. It also provides a bunch of plotting functions to make nice othello board states, and some random other utilities\n",
    "-   \\`tl\\_probing.py\\` is my probe training file. But it was used to train a *second* probe, linear\\_probe\\_L4\\_blank\\_vs\\_color\\_v1.pth . This probe actually didn't work very well for analysing the model (despite getting great accuracy) and I don't know why - it was trained on layer 4, to do a binary classification on blank vs not blank, and on my color vs their color *conditional *on not being blank (ie not evaluated if blank). For some reason, the \"this cell is my color\" direction has a significant dot product with the \"is blank\" direction, and this makes it much worse for eg interpreting neurons. I don't know why!\n",
    "-   \\`tl\\_scratch.py\\` is where I did some initial exploration, including activation patching between different final moves\n",
    "-   \\`tl\\_exploration.py\\` is where I did my most recent exploration, verifying that the probe works, doing probe interventions (CTRL F for \\`newly\\_legal\\`) and using the probe to interpret neurons\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This loads a conversion of the author's synthetic model checkpoint to TransformerLens format. See [this notebook](https://colab.research.google.com/github/neelnanda-io/TransformerLens/blob/main/demos/Othello_GPT.ipynb) for how."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformer_lens.utils as utils\n",
    "cfg = HookedTransformerConfig(\n",
    "    n_layers = 8,\n",
    "    d_model = 512,\n",
    "    d_head = 64,\n",
    "    n_heads = 8,\n",
    "    d_mlp = 2048,\n",
    "    d_vocab = 61,\n",
    "    n_ctx = 59,\n",
    "    act_fn=\"gelu\",\n",
    "    normalization_type=\"LNPre\"\n",
    ")\n",
    "model = HookedTransformer(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# sd = utils.download_file_from_hf(\"NeelNanda/Othello-GPT-Transformer-Lens\", \"synthetic_model.pth\")\n",
    "champion_ship_sd = utils.download_file_from_hf(\"NeelNanda/Othello-GPT-Transformer-Lens\", \"championship_model.pth\")\n",
    "model.load_state_dict(champion_ship_sd)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code to load and convert one of the author's checkpoints to TransformerLens:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing code for the synthetic checkpoint giving the correct outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# An example input\n",
    "sample_input = torch.tensor([[20, 19, 18, 10, 2, 1, 27, 3, 41, 42, 34, 12, 4, 40, 11, 29, 43, 13, 48, 56, 33, 39, 22, 44, 24, 5, 46, 6, 32, 36, 51, 58, 52, 60, 21, 53, 26, 31, 37, 9, 25, 38, 23, 50, 45, 17, 47, 28, 35, 30, 54, 16, 59, 49, 57, 14, 15, 55, 7]])\n",
    "# The argmax of the output (ie the most likely next move from each position)\n",
    "sample_output = torch.tensor([[21, 41, 40, 34, 40, 41,  3, 11, 21, 43, 40, 21, 28, 50, 33, 50, 33,  5,\n",
    "         33,  5, 52, 46, 14, 46, 14, 47, 38, 57, 36, 50, 38, 15, 28, 26, 28, 59,\n",
    "         50, 28, 14, 28, 28, 28, 28, 45, 28, 35, 15, 14, 30, 59, 49, 59, 15, 15,\n",
    "         14, 15,  8,  7,  8]])\n",
    "\n",
    "\n",
    "model(sample_input).argmax(dim=-1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Othello Content\n",
    "Boring setup code to load in 100K sample Othello games, the linear probe, and some utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/home/jsetpal/othello_world/mechanistic_interpretability\")\n",
    "from mech_interp_othello_utils import plot_single_board, to_string, to_int, int_to_label, string_to_label, OthelloBoardState"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We load in a big tensor of 100,000 games, each with 60 moves. This is in the format the model wants, with 1-59 representing the 60 moves, and 0 representing pass.\n",
    "\n",
    "We also load in the same set of games, in the same order, but in \"string\" format - still a tensor of ints but referring to moves with numbers from 0 to 63 rather than in the model's compressed format of 1 to 59"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "OTHELLO_ROOT = Path(\"/home/jsetpal/othello_world/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mechanistic_interpretability.data import ContrastiveDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ds = ContrastiveDataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of games: 100000\n",
      "Length of game: 60\n"
     ]
    }
   ],
   "source": [
    "board_seqs_int = torch.tensor(np.load(OTHELLO_ROOT/\"mechanistic_interpretability/board_seqs_int_small.npy\"), dtype=torch.long) # ds.as_seqs_int() # \n",
    "board_seqs_string = torch.tensor(np.load(OTHELLO_ROOT/\"mechanistic_interpretability/board_seqs_string_small.npy\"), dtype=torch.long) # ds.as_seqs_str() \n",
    "\n",
    "num_games, length_of_game = board_seqs_int.shape\n",
    "print(\"Number of games:\", num_games,)\n",
    "print(\"Length of game:\", length_of_game)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(60)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "board_seqs_int.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(63)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "board_seqs_string.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "stoi_indices = [\n",
    "    0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 29, 30, 31, 32, 33, 34, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63,\n",
    "]\n",
    "alpha = \"ABCDEFGH\"\n",
    "\n",
    "\n",
    "def to_board_label(i):\n",
    "    return f\"{alpha[i//8]}{i%8}\"\n",
    "\n",
    "\n",
    "board_labels = list(map(to_board_label, stoi_indices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'H7'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_board_label(63)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27\n",
      "28\n",
      "35\n",
      "36\n"
     ]
    }
   ],
   "source": [
    "for i in range(63):\n",
    "    if i not in stoi_indices:\n",
    "        print(i)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running the Model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model's context length is 59, not 60, because it's trained to receive the first 59 moves and predict the final 59 moves (ie `[0:-1]` and `[1:]`. Let's run the model on the first 30 moves of game 0!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_score(moves_int, logits, ret_list=True):\n",
    "    discount = 0\n",
    "    aggregate = []\n",
    "    for idx in range(moves_int.shape[0]):\n",
    "        board = OthelloBoardState()\n",
    "        board.update(to_string(moves_int[idx]))\n",
    "    \n",
    "        logit_vec = logits[idx, -1]\n",
    "        log_probs = logit_vec.log_softmax(-1)\n",
    "        # Remove passing\n",
    "        log_probs = log_probs[1:]\n",
    "        assert len(log_probs)==60\n",
    "        \n",
    "        temp_board_state = torch.zeros(64, device=logit_vec.device)\n",
    "        temp_board_state -= 15.\n",
    "        temp_board_state[stoi_indices] = log_probs\n",
    "    \n",
    "        score = board.score(temp_board_state)\n",
    "        if score is not None: aggregate.append(score)\n",
    "        else: discount += 1\n",
    "    print(f'{discount} illegal moves')\n",
    "    if ret_list: return aggregate\n",
    "    return sum(aggregate) / (moves_int.shape[0] - discount)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits: torch.Size([400, 30, 61])\n",
      "32 illegal moves\n"
     ]
    }
   ],
   "source": [
    "moves_int = board_seqs_int[:400, :30]\n",
    "\n",
    "logits = model(moves_int)\n",
    "print(\"logits:\", logits.shape)\n",
    "ret2 = mean_score(moves_int, logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# plt.clf()\n",
    "# plt.hist(ret0, histtype=u'step')\n",
    "# plt.hist(ret1, histtype=u'step')\n",
    "# plt.hist(ret2, histtype=u'step')\n",
    "# plt.savefig('woc.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits: torch.Size([400, 30, 61])\n",
      "38 illegal moves\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[-6,\n",
       " -1,\n",
       " -6,\n",
       " -6,\n",
       " 2,\n",
       " -4,\n",
       " 3,\n",
       " 2,\n",
       " 0,\n",
       " -8,\n",
       " 3,\n",
       " 5,\n",
       " 0,\n",
       " 0,\n",
       " -2,\n",
       " -1,\n",
       " -8,\n",
       " 2,\n",
       " 0,\n",
       " 3,\n",
       " -2,\n",
       " 0,\n",
       " 2,\n",
       " -1,\n",
       " -5,\n",
       " -2,\n",
       " -4,\n",
       " 4,\n",
       " -1,\n",
       " -4,\n",
       " 8,\n",
       " -2,\n",
       " 0,\n",
       " 0,\n",
       " 4,\n",
       " 2,\n",
       " 3,\n",
       " -2,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " -4,\n",
       " 8,\n",
       " -10,\n",
       " 0,\n",
       " 5,\n",
       " -1,\n",
       " 8,\n",
       " 9,\n",
       " -1,\n",
       " 8,\n",
       " -1,\n",
       " -6,\n",
       " -1,\n",
       " 3,\n",
       " -1,\n",
       " 2,\n",
       " 1,\n",
       " -3,\n",
       " -1,\n",
       " 3,\n",
       " 3,\n",
       " -8,\n",
       " -8,\n",
       " 5,\n",
       " -2,\n",
       " -1,\n",
       " -1,\n",
       " 0,\n",
       " -8,\n",
       " -6,\n",
       " -3,\n",
       " 1,\n",
       " 8,\n",
       " 3,\n",
       " 1,\n",
       " 0,\n",
       " -3,\n",
       " 3,\n",
       " 5,\n",
       " -2,\n",
       " -7,\n",
       " -3,\n",
       " 4,\n",
       " -5,\n",
       " -2,\n",
       " 8,\n",
       " 3,\n",
       " 1,\n",
       " 8,\n",
       " -2,\n",
       " -5,\n",
       " -7,\n",
       " -1,\n",
       " 9,\n",
       " -4,\n",
       " 8,\n",
       " -3,\n",
       " -4,\n",
       " -3,\n",
       " 7,\n",
       " -1,\n",
       " 2,\n",
       " 4,\n",
       " -11,\n",
       " 8,\n",
       " 3,\n",
       " 1,\n",
       " -1,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 2,\n",
       " 7,\n",
       " 4,\n",
       " 0,\n",
       " 0,\n",
       " 4,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 4,\n",
       " 0,\n",
       " -1,\n",
       " -3,\n",
       " 4,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 5,\n",
       " -7,\n",
       " -3,\n",
       " -3,\n",
       " -4,\n",
       " -5,\n",
       " -2,\n",
       " -6,\n",
       " 3,\n",
       " 9,\n",
       " 5,\n",
       " 0,\n",
       " 4,\n",
       " -2,\n",
       " 2,\n",
       " 0,\n",
       " -1,\n",
       " 2,\n",
       " 8,\n",
       " 9,\n",
       " 4,\n",
       " 5,\n",
       " -1,\n",
       " 4,\n",
       " -1,\n",
       " 7,\n",
       " -3,\n",
       " -4,\n",
       " 0,\n",
       " 5,\n",
       " -3,\n",
       " 0,\n",
       " -4,\n",
       " -1,\n",
       " 8,\n",
       " -3,\n",
       " -6,\n",
       " 0,\n",
       " 5,\n",
       " -1,\n",
       " -2,\n",
       " -6,\n",
       " 0,\n",
       " -12,\n",
       " 3,\n",
       " -4,\n",
       " -8,\n",
       " 9,\n",
       " -2,\n",
       " 0,\n",
       " -6,\n",
       " 0,\n",
       " 9,\n",
       " -3,\n",
       " -2,\n",
       " 5,\n",
       " 3,\n",
       " 12,\n",
       " 2,\n",
       " 1,\n",
       " -1,\n",
       " -1,\n",
       " -2,\n",
       " 0,\n",
       " 7,\n",
       " 1,\n",
       " 1,\n",
       " -4,\n",
       " -3,\n",
       " 1,\n",
       " 11,\n",
       " 1,\n",
       " -2,\n",
       " 1,\n",
       " 1,\n",
       " 7,\n",
       " 5,\n",
       " -3,\n",
       " 11,\n",
       " -2,\n",
       " 1,\n",
       " 0,\n",
       " 8,\n",
       " 0,\n",
       " 0,\n",
       " -1,\n",
       " 0,\n",
       " 3,\n",
       " 4,\n",
       " -1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " -4,\n",
       " 3,\n",
       " -9,\n",
       " 3,\n",
       " -3,\n",
       " -9,\n",
       " 6,\n",
       " 4,\n",
       " 0,\n",
       " -7,\n",
       " 0,\n",
       " 4,\n",
       " 9,\n",
       " -8,\n",
       " -6,\n",
       " 9,\n",
       " -3,\n",
       " -6,\n",
       " 3,\n",
       " 0,\n",
       " 11,\n",
       " 1,\n",
       " 6,\n",
       " 1,\n",
       " -8,\n",
       " 2,\n",
       " -3,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " -3,\n",
       " -2,\n",
       " 2,\n",
       " 8,\n",
       " -2,\n",
       " -7,\n",
       " 3,\n",
       " 5,\n",
       " 13,\n",
       " 0,\n",
       " 0,\n",
       " -2,\n",
       " 5,\n",
       " -1,\n",
       " 0,\n",
       " -1,\n",
       " 0,\n",
       " 2,\n",
       " 8,\n",
       " -1,\n",
       " -2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " -1,\n",
       " 4,\n",
       " -2,\n",
       " 4,\n",
       " -8,\n",
       " 4,\n",
       " -2,\n",
       " 6,\n",
       " 2,\n",
       " 10,\n",
       " -1,\n",
       " 0,\n",
       " 11,\n",
       " 2,\n",
       " -4,\n",
       " -3,\n",
       " -1,\n",
       " -9,\n",
       " -4,\n",
       " -1,\n",
       " -1,\n",
       " 2,\n",
       " 1,\n",
       " -2,\n",
       " 8,\n",
       " 4,\n",
       " -1,\n",
       " 6,\n",
       " -1,\n",
       " -1,\n",
       " 8,\n",
       " 5,\n",
       " -1,\n",
       " -1,\n",
       " 4,\n",
       " 12,\n",
       " 1,\n",
       " 7,\n",
       " -1,\n",
       " 1,\n",
       " 10,\n",
       " 9,\n",
       " -3,\n",
       " -1,\n",
       " -2,\n",
       " 2,\n",
       " 1,\n",
       " -4,\n",
       " 1,\n",
       " 5,\n",
       " 7,\n",
       " -2,\n",
       " -10,\n",
       " 0,\n",
       " -6,\n",
       " 0,\n",
       " -4,\n",
       " 2,\n",
       " 1,\n",
       " 6,\n",
       " -3,\n",
       " 1,\n",
       " 6,\n",
       " 1,\n",
       " 3,\n",
       " -6,\n",
       " 2,\n",
       " 1,\n",
       " 5,\n",
       " -3,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " -3,\n",
       " 1,\n",
       " 5,\n",
       " 14,\n",
       " 4,\n",
       " 0,\n",
       " -4,\n",
       " 8]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "moves_int = board_seqs_int[-400:, :30]\n",
    "\n",
    "logits = model(moves_int)\n",
    "print(\"logits:\", logits.shape)\n",
    "mean_score(moves_int, logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-26.7173, -14.3825, -22.8553, -20.7587, -17.2164, -22.0967, -17.6001,\n",
       "        -16.1091, -17.9181, -16.6107, -17.6684, -16.2971, -18.9724, -17.0783,\n",
       "        -26.3339, -19.7350, -19.5273, -22.6599, -27.1381, -19.7453, -24.4807,\n",
       "        -19.1345, -23.3022, -15.9375, -27.6966,  -9.5688, -19.8827, -15.9409,\n",
       "        -19.2781, -21.6208, -12.9044, -24.7155, -26.5700, -17.6436, -17.6094,\n",
       "         -8.6965, -11.0773, -17.1337, -25.2136, -16.0457, -14.1063, -20.0750,\n",
       "        -11.9031, -22.3970,  -6.1723,  -5.6357,  -0.1796, -18.2915, -26.9880,\n",
       "        -12.3782, -10.8979, -18.3127, -21.9537,  -9.2534, -19.7104, -21.3561,\n",
       "         -7.6239,  -2.5419,  -2.5366, -12.9368], device='cuda:0',\n",
       "       grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits[0, -1].log_softmax(-1)[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([400, 30, 61])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits[0, -1].argmax().item()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We take the final vector of logits. We convert it to log probs and we then remove the first element (corresponding to passing, and we've filtered out all games with passing) and get the 60 logits. This is 64-4 because the model's vocab is compressed, since the center 4 squares can't be played.\n",
    "\n",
    "We then convert it to an 8 x 8 grid and plot it, with some tensor magic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit_vec = logits[0, -1]\n",
    "log_probs = logit_vec.log_softmax(-1)\n",
    "# Remove passing\n",
    "log_probs = log_probs[1:]\n",
    "assert len(log_probs)==60\n",
    "\n",
    "temp_board_state = torch.zeros(64, device=logit_vec.device)\n",
    "# Set all cells to -15 by default, for a very negative log prob - this means the middle cells don't show up as mattering\n",
    "temp_board_state -= 15.\n",
    "temp_board_state[stoi_indices] = log_probs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now plot this as a board state! We see a crisp distinction from a set of moves that the model clearly thinks are valid (at near uniform probabilities), and a bunch that aren't. Note that by training the model to predict a *uniformly* chosen next move, we incentivise it to be careful about making all valid logits be uniform!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<html>\n",
       "<head><meta charset=\"utf-8\" /></head>\n",
       "<body>\n",
       "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
       "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.30.0.min.js\"></script>                <div id=\"50ad046f-d672-4eb5-ba05-3d783350a0a4\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"50ad046f-d672-4eb5-ba05-3d783350a0a4\")) {                    Plotly.newPlot(                        \"50ad046f-d672-4eb5-ba05-3d783350a0a4\",                        [{\"coloraxis\":\"coloraxis\",\"name\":\"0\",\"x\":[\"0\",\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\"],\"y\":[\"A\",\"B\",\"C\",\"D\",\"E\",\"F\",\"G\",\"H\"],\"z\":[[-26.717317581176758,-14.38249397277832,-22.85529136657715,-20.758712768554688,-17.216421127319336,-22.09673500061035,-17.600072860717773,-16.10906410217285],[-17.9180965423584,-16.61072540283203,-17.66844367980957,-16.297080993652344,-18.97241973876953,-17.078277587890625,-26.333913803100586,-19.73496437072754],[-19.527292251586914,-22.659910202026367,-27.138147354125977,-19.745281219482422,-24.480735778808594,-19.134475708007812,-23.302209854125977,-15.937524795532227],[-27.696630477905273,-9.568792343139648,-19.88265609741211,-15.0,-15.0,-15.940903663635254,-19.2780704498291,-21.62080192565918],[-12.904411315917969,-24.715532302856445,-26.57001304626465,-15.0,-15.0,-17.64360809326172,-17.6093692779541,-8.696479797363281],[-11.077286720275879,-17.133691787719727,-25.21363639831543,-16.04569435119629,-14.106283187866211,-20.075048446655273,-11.90310287475586,-22.396957397460938],[-6.172336101531982,-5.635737895965576,-0.17958229780197144,-18.291454315185547,-26.988000869750977,-12.37822437286377,-10.897871017456055,-18.312664031982422],[-21.953651428222656,-9.253368377685547,-19.710430145263672,-21.356101989746094,-7.623902797698975,-2.5418756008148193,-2.536609411239624,-12.936816215515137]],\"type\":\"heatmap\",\"xaxis\":\"x\",\"yaxis\":\"y\",\"hovertemplate\":\"x: %{x}\\u003cbr\\u003ey: %{y}\\u003cbr\\u003ecolor: %{z}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"scaleanchor\":\"y\",\"constrain\":\"domain\",\"title\":{\"text\":\"x\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"autorange\":\"reversed\",\"constrain\":\"domain\",\"title\":{\"text\":\"y\"}},\"coloraxis\":{\"colorscale\":[[0.0,\"rgb(247,251,255)\"],[0.125,\"rgb(222,235,247)\"],[0.25,\"rgb(198,219,239)\"],[0.375,\"rgb(158,202,225)\"],[0.5,\"rgb(107,174,214)\"],[0.625,\"rgb(66,146,198)\"],[0.75,\"rgb(33,113,181)\"],[0.875,\"rgb(8,81,156)\"],[1.0,\"rgb(8,48,107)\"]],\"cmin\":-27.696630477905273,\"cmax\":0},\"title\":{\"text\":\"Example Log Probs\"}},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('50ad046f-d672-4eb5-ba05-3d783350a0a4');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                            </script>        </div>\n",
       "</body>\n",
       "</html>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_square_as_board(state, diverging_scale=True, **kwargs):\n",
    "    \"\"\"Takes a square input (8 by 8) and plot it as a board. Can do a stack of boards via facet_col=0\"\"\"\n",
    "    if diverging_scale:\n",
    "        imshow(state, y=[i for i in alpha], x=[str(i) for i in range(8)], color_continuous_scale=\"RdBu\", color_continuous_midpoint=0., aspect=\"equal\", **kwargs)\n",
    "    else:\n",
    "        imshow(state, y=[i for i in alpha], x=[str(i) for i in range(8)], color_continuous_scale=\"Blues\", color_continuous_midpoint=None, aspect=\"equal\", **kwargs)\n",
    "plot_square_as_board(temp_board_state.reshape(8, 8), zmax=0, diverging_scale=False, title=\"Example Log Probs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mechanistic_interpretability.tl_probing_v1 import seq_to_state_stack, state_stack_to_one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.0140, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(1.0310, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(1.0225, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.9979, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(1.0166, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(1.0117, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.9916, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(1.0224, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.9855, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(1.0365, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.9753, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.9273, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(1.0119, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.9214, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(1.0101, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.9647, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.9670, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.9852, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.9530, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.9461, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.9532, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.9529, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.9479, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(1.0105, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.9325, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.9555, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.9198, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(1.0285, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.9571, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.9604, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.8812, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.8314, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.9267, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.9223, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.8626, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.9870, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.8745, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.8701, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.9393, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.9244, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.9144, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.9222, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.8317, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.8496, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.8629, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.8358, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.9239, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.9045, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.8747, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.8280, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.9000, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.8330, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.8941, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.8428, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.8128, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.8842, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.8215, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.8381, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.8751, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.7592, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.8440, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.8063, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.8266, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.8272, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.8517, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.7985, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.7890, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.8102, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.8063, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.7929, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.7949, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.8093, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.7947, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.8092, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.7606, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.7756, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.7723, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.7844, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.7868, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.7540, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.7492, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.7735, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.7844, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.7743, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.7795, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.7677, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.7130, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.8282, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.7681, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.7454, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.7470, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.6131, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.7263, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.7504, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.7148, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.7243, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.7468, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.7129, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.6572, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.7865, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.7203, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.6491, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.7016, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.6171, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.6834, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.6430, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.6699, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.6835, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.6374, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.6283, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.6596, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.7027, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.6353, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.5811, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.6389, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.6430, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.6095, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.6255, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.5512, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.5330, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.6069, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.5290, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.5564, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.5265, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.5548, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.5580, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.5159, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.4776, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.5769, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.5067, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.4711, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.5701, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.5437, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.5053, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.4784, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.4347, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.4447, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.5113, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.5060, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.4410, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.4895, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.4756, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.4477, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.4392, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.4642, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.4574, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.4305, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.5144, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.4286, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.4555, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.4499, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.4348, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.4243, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.4378, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.4434, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.4356, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.4457, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.4241, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.4217, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.3663, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.3937, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.4360, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.4354, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.3713, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.4150, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.4363, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.4070, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.3261, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.3744, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.4279, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.4175, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.4275, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.3975, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.3878, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.4257, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.3977, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.4019, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.3891, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.3937, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.4196, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.3956, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.3847, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.3830, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.4327, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.3930, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.3847, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.3838, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.3655, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.3844, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.3752, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.3819, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.4018, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.3975, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.3782, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.3720, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.3516, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.3847, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.3709, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.3866, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.3494, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.4062, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.3522, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.3742, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.3640, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.3898, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.3737, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.3638, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.3612, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.3708, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.3649, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.3734, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.4063, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.3742, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.3721, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.3764, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.3152, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.3659, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.3533, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.3711, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.4293, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.3476, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.3814, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.3685, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.3816, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.3672, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.3631, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.3643, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.3816, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.3561, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.3680, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.3656, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.3867, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.3654, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.3684, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.3705, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.3147, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.3560, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.3665, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.3602, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.3980, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.3624, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.3368, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.3834, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.3870, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.3563, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.3597, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.3655, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.3811, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.3727, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.3416, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.3712, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.3472, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.3540, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.3645, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.3606, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.3631, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.3439, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.3807, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.3523, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.3604, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.3426, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.3715, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.3585, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.3642, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.3573, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.3537, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.3602, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.3472, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.3630, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.3406, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.3540, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.3842, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.3336, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.3484, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.3777, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.3609, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.3526, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.3493, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.3621, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.3302, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.3652, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.3371, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.3601, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.3303, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.3680, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.3373, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.3558, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.3276, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.3563, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.3601, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.3433, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.3298, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.3520, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.3386, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.3597, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.3641, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.3606, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.3405, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.3439, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.3812, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.3631, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.3398, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.3564, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.3133, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.3537, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.3447, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.3519, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.3477, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.3432, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.3489, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.3564, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.3473, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.3448, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.3457, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.3599, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.3302, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.3457, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.3483, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.3427, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.3811, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.3576, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.3407, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.3446, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.3478, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.3599, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.3289, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.3526, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.3472, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.3483, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.3557, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.3286, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.3811, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.3469, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.3367, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.3517, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.3641, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.3330, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.3516, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.3562, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.3302, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.3442, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.3369, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.3472, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.3723, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.3305, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.3592, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.3418, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.3465, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.3408, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.3444, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.3389, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.3625, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.3302, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.3368, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.3434, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.4151, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.3289, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.3331, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.3654, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.3302, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.3440, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.3409, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.3411, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.3302, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.3478, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.3368, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.3368, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.3472, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.3289, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.3472, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.3367, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.3807, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.3524, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.3305, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.3329, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.3641, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.3445, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.3406, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.3297, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.3631, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.3369, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.3407, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.3444, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.3302, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.3445, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.3366, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.3404, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.3306, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.3368, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.3405, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.3363, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.3631, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.3328, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.3326, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.3552, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.3310, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.3437, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.3251, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.3512, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "tensor(0.3302, device='cuda:0', grad_fn=<DivBackward1>)\n"
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "layer = 6\n",
    "batch_size = 256\n",
    "lr = 1e-4\n",
    "wd = 0.01\n",
    "pos_start = 5\n",
    "pos_end = model.cfg.n_ctx - 5\n",
    "length = pos_end - pos_start\n",
    "\n",
    "linear_probe = torch.randn(\n",
    "    model.cfg.d_model, 2, requires_grad=False, device=\"cuda\"\n",
    ")/np.sqrt(model.cfg.d_model)\n",
    "linear_probe.requires_grad = True\n",
    "optimizer = torch.optim.AdamW([linear_probe], lr=lr, betas=(0.9, 0.99), weight_decay=wd)\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "softmax = torch.nn.Softmax(dim=-1)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for games_str, y in DataLoader(ds, shuffle=True, batch_size=batch_size):\n",
    "        games_int = ds.as_seqs_int(games_str.detach().clone())\n",
    "\n",
    "        state_stack = torch.stack(\n",
    "            [torch.tensor(seq_to_state_stack(game)) for game in games_str]\n",
    "        )\n",
    "        state_stack = state_stack[:, pos_start:pos_end, :, :]\n",
    "        state_stack_one_hot = state_stack_to_one_hot(state_stack).cuda()\n",
    "        \n",
    "        with torch.inference_mode():\n",
    "            _, cache = model.run_with_cache(games_int.cuda()[:, :-1], return_type=None)\n",
    "            resid_post = cache[\"resid_post\", layer][:, pos_start:pos_end]\n",
    "        probe_out = einsum(\"batch pos d_model, d_model pred -> batch pred\", resid_post, linear_probe)\n",
    "\n",
    "        # probe_correct_log_probs = einops.reduce(\n",
    "        #     probe_out.log_softmax(0) * state_stack_one_hot,\n",
    "        #     \"batch pos pred -> batch pred\",\n",
    "        #     \"mean\"\n",
    "        # ) * probe_out.shape[1]\n",
    "        \n",
    "        # loss = loss_fn(y.cuda(), torch.e**probe_correct_log_probs)\n",
    "        loss = loss_fn(y.cuda(), probe_out.softmax(dim=-1))\n",
    "        print(loss)\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(linear_probe, 'skill_probe.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "skill_intervention_vector = linear_probe[:, 0] - linear_probe[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 5.7978e-02,  1.1068e-01,  2.3116e-02,  8.1939e-02, -5.1484e-02,\n",
       "         7.9068e-02,  7.8090e-02, -2.7557e-02,  1.0070e-02,  2.0353e-02,\n",
       "        -3.1920e-02,  5.1530e-02,  4.9452e-02, -3.8679e-03, -2.1139e-02,\n",
       "         9.1300e-02,  4.4707e-02, -3.0904e-02,  1.1623e-02, -4.2785e-02,\n",
       "        -8.5112e-02, -1.2063e-02, -2.0106e-02,  1.2375e-02, -4.9349e-02,\n",
       "         1.5547e-02,  5.5086e-02,  7.2022e-02, -1.1563e-02,  1.4543e-02,\n",
       "         5.5412e-02, -7.9971e-02,  7.2672e-02, -6.1554e-03, -1.7584e-02,\n",
       "         1.6050e-01,  1.3123e-02, -1.2831e-02,  2.3952e-02,  5.0120e-02,\n",
       "         7.9013e-02,  1.4330e-02, -1.2310e-01, -3.5990e-02,  1.4748e-01,\n",
       "        -7.9505e-02, -6.1255e-02,  8.5031e-02,  1.8951e-02,  4.2056e-02,\n",
       "        -2.3299e-02, -2.2425e-02,  4.4497e-02,  6.7761e-02,  1.9736e-02,\n",
       "        -5.9430e-02,  6.3017e-02, -3.5664e-02,  1.2342e-02, -1.0197e-01,\n",
       "         1.8769e-02, -5.9005e-02, -4.7482e-02, -4.3249e-03, -1.8825e-02,\n",
       "        -3.7061e-02,  2.0333e-02, -2.5779e-05,  1.7858e-02, -4.1666e-02,\n",
       "         4.0600e-02,  2.1704e-02, -1.1971e-01, -6.0314e-02,  1.7764e-01,\n",
       "         1.0002e-02, -4.2383e-02, -1.6648e-02,  9.9949e-02, -1.3735e-01,\n",
       "         2.4286e-02,  7.9982e-03, -2.2146e-02, -6.4139e-03,  3.5013e-02,\n",
       "        -3.5499e-03, -3.4786e-02,  9.7651e-02, -1.9029e-02, -3.8815e-02,\n",
       "         1.2769e-03,  5.0105e-02, -2.2098e-02,  4.7854e-02,  7.4243e-02,\n",
       "        -7.5157e-02, -4.8035e-02, -3.4691e-02, -2.4605e-02, -5.7005e-02,\n",
       "         9.3960e-02, -1.6824e-01,  2.1681e-02,  2.2499e-03, -6.3510e-02,\n",
       "        -1.1268e-01,  5.0349e-02,  2.2039e-02,  1.0459e-01, -1.1691e-01,\n",
       "         1.7178e-02, -1.9181e-02,  5.9302e-02,  5.2900e-02,  6.5112e-02,\n",
       "        -3.9266e-02, -9.1298e-03, -3.7171e-02,  1.0595e-01, -1.3359e-02,\n",
       "        -5.2854e-02, -9.5018e-03, -1.4750e-01, -1.7305e-02,  5.4663e-02,\n",
       "        -2.3650e-02, -2.3522e-02,  1.3696e-01, -1.9526e-02, -1.6582e-02,\n",
       "         1.8027e-02,  8.7390e-02, -3.4992e-03,  4.5925e-02,  1.2462e-01,\n",
       "        -4.0544e-02,  3.4521e-02, -1.2125e-02, -3.0007e-02,  4.6573e-02,\n",
       "        -2.2718e-02,  3.9077e-02, -7.2784e-02,  1.5022e-02, -1.5686e-02,\n",
       "         9.6983e-02, -8.0487e-03, -3.5196e-02,  1.5536e-02,  1.3587e-01,\n",
       "         6.2424e-02,  4.9716e-02, -3.7831e-02,  1.5132e-02,  6.7181e-02,\n",
       "         4.3795e-02,  1.1627e-01, -9.9710e-03,  8.8786e-02, -3.3297e-02,\n",
       "        -1.1400e-02, -2.3132e-02,  3.1891e-02, -6.5622e-02,  3.3911e-02,\n",
       "         2.6536e-02, -1.5930e-02, -1.4074e-02, -4.7242e-02, -1.7844e-03,\n",
       "        -1.2921e-01, -1.9542e-02, -2.3107e-02,  4.1754e-02, -8.2260e-02,\n",
       "        -1.4272e-01, -5.0172e-02,  1.0535e-02, -4.0473e-03, -6.3744e-02,\n",
       "         1.3160e-01,  2.5421e-02,  5.2497e-03, -3.5093e-03, -8.4103e-02,\n",
       "         1.2565e-01, -3.1245e-02, -7.8699e-02, -2.2014e-02,  1.0624e-02,\n",
       "        -5.3169e-02, -1.0841e-01, -8.4873e-03,  4.6188e-02, -9.5656e-02,\n",
       "        -4.2064e-02,  7.1745e-03,  7.2203e-02,  7.7292e-02,  1.1418e-01,\n",
       "        -1.0438e-01,  1.6157e-03,  7.3544e-02,  3.2691e-03, -3.3145e-02,\n",
       "         9.7247e-02, -1.0066e-01, -1.1121e-01, -3.0178e-02, -6.2656e-02,\n",
       "        -2.7247e-02,  6.7511e-02,  2.7813e-02, -7.4430e-02,  8.2121e-03,\n",
       "         5.2140e-02, -7.1876e-02,  9.8008e-02, -8.4116e-02, -8.9801e-02,\n",
       "         7.0890e-02,  7.7212e-02,  4.8270e-02,  3.9965e-02,  4.8822e-02,\n",
       "         5.6002e-02,  9.5879e-02,  7.2714e-02, -1.9953e-01, -6.1749e-02,\n",
       "         4.0749e-04,  3.5519e-03, -4.7527e-02, -2.6401e-02, -7.9267e-02,\n",
       "         1.4775e-01, -6.7142e-03,  4.6183e-02, -8.2230e-02, -2.2655e-02,\n",
       "         1.3620e-01,  5.0147e-02, -2.9808e-02,  1.1761e-01, -6.9504e-02,\n",
       "         1.0010e-01, -6.1718e-03, -7.8399e-03, -5.9919e-02, -2.4249e-02,\n",
       "         5.3409e-02,  1.8545e-02, -8.7183e-02, -3.1521e-02, -1.0146e-01,\n",
       "         4.7759e-02, -6.7831e-02, -5.7802e-02,  5.1630e-02, -1.6299e-02,\n",
       "         1.6359e-02, -1.5980e-02,  2.9144e-03, -5.8630e-02,  6.0464e-02,\n",
       "        -1.1825e-01, -2.7365e-02,  8.3920e-02, -6.5680e-02, -9.3566e-02,\n",
       "        -6.2838e-02, -4.8618e-02, -6.7247e-02,  1.9203e-02,  1.1423e-01,\n",
       "        -7.7118e-02,  1.3986e-02,  4.5839e-02, -1.3343e-01, -9.9965e-02,\n",
       "        -6.6032e-02, -8.5869e-03,  1.1096e-01,  7.9869e-03,  3.7726e-02,\n",
       "         2.1744e-02, -4.9561e-02,  9.5703e-02,  6.9827e-02,  3.1477e-02,\n",
       "        -6.1970e-02, -7.7673e-02, -4.4426e-02,  3.5191e-03, -4.5426e-02,\n",
       "        -2.9723e-02, -3.7416e-02, -1.6163e-01, -6.1205e-02, -9.9109e-02,\n",
       "        -2.9458e-02, -6.7039e-02,  3.9645e-02, -7.4289e-03, -1.0444e-01,\n",
       "         2.5292e-02,  2.0933e-02, -5.2895e-02,  7.6229e-02,  7.9758e-02,\n",
       "         1.2693e-01,  3.6182e-02, -3.5662e-02, -1.0601e-02, -3.6767e-02,\n",
       "         1.6240e-02, -1.3239e-02,  3.6843e-02, -1.2976e-02,  1.1437e-01,\n",
       "         8.4941e-02, -3.5735e-02, -7.1786e-02,  9.9676e-03,  3.8121e-02,\n",
       "         3.5640e-02, -3.2719e-02,  2.5593e-02, -5.1789e-02, -6.1277e-02,\n",
       "         9.3305e-02,  2.9966e-03, -2.7354e-02, -4.3517e-02,  7.5300e-02,\n",
       "         6.4109e-02,  1.1498e-01, -2.1098e-02, -9.4244e-03,  9.7722e-02,\n",
       "        -4.0792e-02,  8.8548e-04,  1.3585e-01,  3.9110e-02,  2.1202e-02,\n",
       "        -6.8680e-02,  5.0028e-02, -1.8898e-02, -3.2489e-02, -6.3629e-02,\n",
       "         1.5451e-02, -7.7436e-02, -7.2336e-02,  7.5122e-02,  7.0643e-02,\n",
       "        -2.1762e-02,  1.2143e-02,  4.5149e-02, -3.3443e-02, -4.1030e-02,\n",
       "         2.2990e-02, -8.4972e-02,  9.6278e-03,  6.6141e-02,  9.9444e-02,\n",
       "        -2.3332e-03, -7.1474e-02,  6.0433e-02, -1.2874e-01, -5.9803e-02,\n",
       "        -4.8686e-02,  5.4742e-02, -9.1137e-02,  1.9858e-02, -1.1835e-02,\n",
       "         9.7667e-02,  9.5463e-02,  3.1383e-02, -7.0858e-03,  9.6136e-02,\n",
       "        -7.4663e-02, -1.0660e-01, -1.6938e-02, -5.8278e-02,  7.6740e-02,\n",
       "         2.7261e-02, -5.2739e-02,  5.8101e-02,  3.1779e-02,  5.5644e-02,\n",
       "         1.2158e-02,  8.9521e-02,  2.1425e-02, -4.3364e-02,  1.4871e-02,\n",
       "        -2.1965e-02,  5.2945e-02,  1.7238e-01,  9.2772e-02, -5.0548e-02,\n",
       "        -1.4832e-01, -3.2585e-02,  8.1832e-02,  8.0179e-02,  6.7032e-02,\n",
       "         5.7931e-02,  7.7902e-02, -6.7202e-02, -9.4419e-02, -2.2807e-02,\n",
       "        -9.3690e-02, -2.0546e-02,  3.7237e-03, -1.1807e-01,  7.7627e-03,\n",
       "         5.9219e-03, -3.9005e-02, -8.5971e-02, -7.2157e-02, -6.8380e-02,\n",
       "         1.4734e-02,  3.6920e-02,  1.0306e-01,  1.8482e-02,  7.4891e-02,\n",
       "        -5.2716e-02, -7.2527e-02,  1.5726e-02,  3.1073e-02,  1.9517e-01,\n",
       "         1.7053e-02, -1.3476e-01,  1.0034e-01, -8.1523e-02,  6.2912e-02,\n",
       "         2.1206e-02,  1.7915e-02, -9.4165e-02,  6.7437e-02, -4.7183e-02,\n",
       "         2.1329e-02,  5.1680e-02, -6.0254e-02,  5.1768e-02, -1.4488e-01,\n",
       "         6.2277e-03,  2.9966e-02,  1.0286e-02,  1.1003e-01, -2.1302e-01,\n",
       "        -1.5559e-02, -1.2798e-01, -6.0521e-03,  1.2705e-01,  7.0466e-02,\n",
       "        -4.1548e-02,  4.0111e-02,  2.7736e-02,  6.8230e-03,  3.3503e-03,\n",
       "         1.0071e-01, -4.6505e-02, -3.4354e-03, -4.7829e-02, -5.4245e-02,\n",
       "         2.0292e-02,  1.9210e-02, -2.9242e-03, -1.7200e-02, -3.2161e-02,\n",
       "        -5.5669e-02,  1.9310e-02,  6.1672e-02,  6.4210e-02,  5.3040e-02,\n",
       "        -7.1364e-02, -1.2992e-01, -4.6114e-02,  1.4327e-01, -3.2529e-02,\n",
       "        -1.7384e-02,  1.9899e-02, -1.4004e-02, -9.7197e-02, -1.2494e-02,\n",
       "        -2.1756e-02, -6.9665e-02, -8.1028e-04,  2.7116e-03,  2.6668e-02,\n",
       "        -1.5115e-02,  4.6054e-02, -1.8666e-02, -1.4375e-01, -6.9028e-02,\n",
       "         5.0771e-02,  3.9890e-02, -4.0346e-02,  1.3085e-02, -7.0114e-03,\n",
       "         5.0341e-02, -1.7437e-02,  4.5074e-02, -3.2548e-02, -1.5077e-02,\n",
       "         6.2126e-03, -2.6646e-02, -9.4871e-03, -3.9866e-02,  3.6615e-02,\n",
       "         6.2418e-02,  6.3554e-02], device='cuda:0', grad_fn=<SubBackward0>)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skill_intervention_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = model.blocks[6].mlp.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "d['b_out'] += skill_intervention_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.blocks[6].mlp.load_state_dict(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits: torch.Size([400, 30, 61])\n",
      "28 illegal moves\n"
     ]
    }
   ],
   "source": [
    "moves_int = board_seqs_int[:400, :30]\n",
    "\n",
    "logits = model(moves_int)\n",
    "print(\"logits:\", logits.shape)\n",
    "ret2 = mean_score(moves_int, logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30 illegal moves\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.32972972972972975"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_score(moves_int, logits, ret_list=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(ret0)\n",
    "plt.savefig('updated_ood.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiwAAAGdCAYAAAAxCSikAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8fJSN1AAAACXBIWXMAAA9hAAAPYQGoP6dpAAAsk0lEQVR4nO3dfXRU9YH/8c+EJJOQh8kDJJPQAEEQCCKglDRqu1qyBqQsHthWeqiLLoWuCyrG+hCPYGXVKD5FMCWr7aKe41N7jkCru3hoULHHGDSU7ooWiETIApMIJBmSkAeS+/sjP8YdCZrATO53Ju/XOXPC3MdP7pmaT+/c+70Oy7IsAQAAGCzC7gAAAADfhsICAACMR2EBAADGo7AAAADjUVgAAIDxKCwAAMB4FBYAAGA8CgsAADBepN0Bzkd3d7eOHDmihIQEORwOu+MAAIA+sCxLJ0+eVGZmpiIi+nfOJCQLy5EjR5SVlWV3DAAAcB5qa2v1ne98p1/rhGRhSUhIkNTzCycmJtqcBgAA9IXX61VWVpbv73h/hGRhOfM1UGJiIoUFAIAQcz6Xc/T7otsdO3Zo7ty5yszMlMPh0ObNm8+57L/8y7/I4XCopKTEb/qJEye0aNEiJSYmKikpSUuWLFFzc3N/owAAgEGi34WlpaVFU6ZMUWlp6Tcut2nTJn344YfKzMw8a96iRYu0Z88ebdu2TW+++aZ27NihZcuW9TcKAAAYJPr9ldDs2bM1e/bsb1zm8OHDuvXWW/X2229rzpw5fvM+++wzbd26VR999JGmT58uSVq/fr2uu+46PfHEE70WHAAAMLgFfByW7u5u3Xjjjbrrrrs0adKks+ZXVFQoKSnJV1YkKT8/XxEREaqsrOx1m+3t7fJ6vX4vAAAweAS8sDz22GOKjIzUbbfd1ut8j8ejtLQ0v2mRkZFKSUmRx+PpdZ3i4mK5XC7fi1uaAQAYXAJaWKqqqvTMM8/ohRdeCOiAbkVFRWpqavK9amtrA7ZtAABgvoAWlvfff1/19fUaOXKkIiMjFRkZqYMHD+rOO+/U6NGjJUlut1v19fV+650+fVonTpyQ2+3udbtOp9N3CzO3MgMAMPgEdByWG2+8Ufn5+X7TCgoKdOONN+rmm2+WJOXl5amxsVFVVVW6/PLLJUnbt29Xd3e3cnNzAxkHAACEiX4XlubmZlVXV/ve19TUaPfu3UpJSdHIkSOVmprqt3xUVJTcbrfGjx8vSZo4caJmzZqlpUuXqqysTJ2dnVqxYoUWLlzIHUIAAKBX/f5K6OOPP9a0adM0bdo0SVJhYaGmTZum1atX93kbL7/8siZMmKCZM2fquuuu01VXXaXnnnuuv1EAAMAg4bAsy7I7RH95vV65XC41NTVxPQsAACHiQv5+B/y2ZgAAgECjsAAAAOOF5NOaAfTd0eajamhvsDtGvyQ7k5URn2F3DAAGobAAYexo81HN2zJPp06fsjtKv8RGxmrLvC2UFgA+FBYgjDW0N+jU6VMq/n6xxrjG2B2nTw40HVDR+0VqaG+gsADwobAAg8AY1xjlpObYHQMAzhsX3QIAAONRWAAAgPEoLAAAwHgUFgAAYDwKCwAAMB6FBQAAGI/CAgAAjEdhAQAAxqOwAAAA41FYAACA8SgsAADAeBQWAABgPAoLAAAwHoUFAAAYj8ICAACMR2EBAADGo7AAAADjUVgAAIDxKCwAAMB4FBYAAGA8CgsAADAehQUAABiPwgIAAIxHYQEAAMajsAAAAONRWAAAgPEoLAAAwHgUFgAAYDwKCwAAMB6FBQAAGI/CAgAAjEdhAQAAxqOwAAAA41FYAACA8SgsAADAeP0uLDt27NDcuXOVmZkph8OhzZs3++Z1dnbqnnvu0eTJkxUXF6fMzEz90z/9k44cOeK3jRMnTmjRokVKTExUUlKSlixZoubm5gv+ZQAAQHjqd2FpaWnRlClTVFpaeta81tZW7dq1S6tWrdKuXbv0xhtvaO/evfqHf/gHv+UWLVqkPXv2aNu2bXrzzTe1Y8cOLVu27Px/CwAAENYi+7vC7NmzNXv27F7nuVwubdu2zW/as88+qxkzZujQoUMaOXKkPvvsM23dulUfffSRpk+fLklav369rrvuOj3xxBPKzMw8j18DAACEs6Bfw9LU1CSHw6GkpCRJUkVFhZKSknxlRZLy8/MVERGhysrKXrfR3t4ur9fr9wIAAINHUAtLW1ub7rnnHv30pz9VYmKiJMnj8SgtLc1vucjISKWkpMjj8fS6neLiYrlcLt8rKysrmLEBAIBhglZYOjs79ZOf/ESWZWnDhg0XtK2ioiI1NTX5XrW1tQFKCQAAQkG/r2HpizNl5eDBg9q+fbvv7Iokud1u1dfX+y1/+vRpnThxQm63u9ftOZ1OOZ3OYEQFAAAhIOBnWM6Ulf379+tPf/qTUlNT/ebn5eWpsbFRVVVVvmnbt29Xd3e3cnNzAx0HAACEgX6fYWlublZ1dbXvfU1NjXbv3q2UlBRlZGToH//xH7Vr1y69+eab6urq8l2XkpKSoujoaE2cOFGzZs3S0qVLVVZWps7OTq1YsUILFy7kDiEAANCrfheWjz/+WNdcc43vfWFhoSRp8eLF+tWvfqU//OEPkqSpU6f6rffOO+/o6quvliS9/PLLWrFihWbOnKmIiAgtWLBA69atO89fAQAAhLt+F5arr75almWdc/43zTsjJSVFr7zySn93DeA8fV7frO62Jrtj9EmNl1GvAZwtKBfdAjBD/cl2SdLtr+9Wd9uXNqfpm4iYw4rL7smek/rtywMYHCgsQBg7eapTkvTLv79YPxg9zeY0fbPji79oQ/VX2QFAorAAg0JWylBdMsJld4w+qfEOtTsCAAMFfWh+AACAC0VhAQAAxqOwAAAA41FYAACA8SgsAADAeBQWAABgPAoLAAAwHoUFAAAYj8ICAACMR2EBAADGo7AAAADjUVgAAIDxKCwAAMB4FBYAAGA8CgsAADAehQUAABiPwgIAAIxHYQEAAMajsAAAAONRWAAAgPEoLAAAwHgUFgAAYDwKCwAAMB6FBQAAGI/CAgAAjEdhAQAAxqOwAAAA41FYAACA8SgsAADAeBQWAABgPAoLAAAwHoUFAAAYj8ICAACMR2EBAADGo7AAAADjUVgAAIDxKCwAAMB4/S4sO3bs0Ny5c5WZmSmHw6HNmzf7zbcsS6tXr1ZGRoZiY2OVn5+v/fv3+y1z4sQJLVq0SImJiUpKStKSJUvU3Nx8Qb8IAAAIX/0uLC0tLZoyZYpKS0t7nb927VqtW7dOZWVlqqysVFxcnAoKCtTW1uZbZtGiRdqzZ4+2bdumN998Uzt27NCyZcvO/7cAAABhLbK/K8yePVuzZ8/udZ5lWSopKdH999+vefPmSZJeeuklpaena/PmzVq4cKE+++wzbd26VR999JGmT58uSVq/fr2uu+46PfHEE8rMzLyAXwcAAISjgF7DUlNTI4/Ho/z8fN80l8ul3NxcVVRUSJIqKiqUlJTkKyuSlJ+fr4iICFVWVva63fb2dnm9Xr8XAAAYPAJaWDwejyQpPT3db3p6erpvnsfjUVpamt/8yMhIpaSk+Jb5uuLiYrlcLt8rKysrkLEBAIDhQuIuoaKiIjU1NfletbW1dkcCAAADKKCFxe12S5Lq6ur8ptfV1fnmud1u1dfX+80/ffq0Tpw44Vvm65xOpxITE/1eAABg8AhoYcnOzpbb7VZ5eblvmtfrVWVlpfLy8iRJeXl5amxsVFVVlW+Z7du3q7u7W7m5uYGMAwAAwkS/7xJqbm5WdXW1731NTY12796tlJQUjRw5UitXrtRDDz2kcePGKTs7W6tWrVJmZqauv/56SdLEiRM1a9YsLV26VGVlZers7NSKFSu0cOFC7hACAAC96ndh+fjjj3XNNdf43hcWFkqSFi9erBdeeEF33323WlpatGzZMjU2Nuqqq67S1q1bFRMT41vn5Zdf1ooVKzRz5kxFRERowYIFWrduXQB+HQAAEI76XViuvvpqWZZ1zvkOh0Nr1qzRmjVrzrlMSkqKXnnllf7uGgAADFIhcZcQAAAY3CgsAADAeBQWAABgPAoLAAAwHoUFAAAYj8ICAACMR2EBAADGo7AAAADjUVgAAIDxKCwAAMB4FBYAAGA8CgsAADAehQUAABiPwgIAAIxHYQEAAMajsAAAAONRWAAAgPEoLAAAwHgUFgAAYDwKCwAAMB6FBQAAGI/CAgAAjEdhAQAAxqOwAAAA41FYAACA8SgsAADAeBQWAABgPAoLAAAwHoUFAAAYj8ICAACMR2EBAADGo7AAAADjUVgAAIDxKCwAAMB4FBYAAGA8CgsAADAehQUAABiPwgIAAIxHYQEAAMajsAAAAONRWAAAgPECXli6urq0atUqZWdnKzY2VhdddJH+7d/+TZZl+ZaxLEurV69WRkaGYmNjlZ+fr/379wc6CgAACBMBLyyPPfaYNmzYoGeffVafffaZHnvsMa1du1br16/3LbN27VqtW7dOZWVlqqysVFxcnAoKCtTW1hboOAAAIAxEBnqDH3zwgebNm6c5c+ZIkkaPHq1XX31VO3fulNRzdqWkpET333+/5s2bJ0l66aWXlJ6ers2bN2vhwoWBjgQAAEJcwM+wXHHFFSovL9e+ffskSX/961/15z//WbNnz5Yk1dTUyOPxKD8/37eOy+VSbm6uKioqet1me3u7vF6v3wsAAAweAT/Dcu+998rr9WrChAkaMmSIurq69PDDD2vRokWSJI/HI0lKT0/3Wy89Pd037+uKi4v14IMPBjoqAAAIEQE/w/K73/1OL7/8sl555RXt2rVLL774op544gm9+OKL573NoqIiNTU1+V61tbUBTAwAAEwX8DMsd911l+69917ftSiTJ0/WwYMHVVxcrMWLF8vtdkuS6urqlJGR4Vuvrq5OU6dO7XWbTqdTTqcz0FEBAECICPgZltbWVkVE+G92yJAh6u7uliRlZ2fL7XarvLzcN9/r9aqyslJ5eXmBjgMAAMJAwM+wzJ07Vw8//LBGjhypSZMm6S9/+Yueeuop/fM//7MkyeFwaOXKlXrooYc0btw4ZWdna9WqVcrMzNT1118f6DgAACAMBLywrF+/XqtWrdK//uu/qr6+XpmZmfrFL36h1atX+5a5++671dLSomXLlqmxsVFXXXWVtm7dqpiYmEDHAQAAYSDghSUhIUElJSUqKSk55zIOh0Nr1qzRmjVrAr17AAAQhgJeWACEsMZaqfW4rRGiG6u/+nkk+twLDk2VkrIGKBUAu1FYAPRorJVKZ0idrbbGyIqOkkZkKOud26SOznMvGDVUWr6T0gIMEhQWAD1aj/eUlfnPS8Muti1G7cFPpX3Fqr1mnXJG5fS+0LF90htLezJTWIBBgcICwN+wi6XMqbbtvqOpo+dn0lhbcwAwS8DHYQEAAAg0zrAAwWbjhax9voBV6vmaxSC1J1r1yeGmXufFHGvWWEnVXzarzep9mYGWHBetEUmxdscAwhaFBQgmmy9k7fMFrGdEDe25+8ZGCbFRkqQntu3T2raWXpeZ5KjRW07p9td2a48hhSU2aoj+dOffUVqAIKGwAMFk84WsfbqA9f8y4FbhtISe54Y9c8NUZSeO73WZmGMuaZP0zMKpahs2eSDj9aq6vlkrX9+thpYOCgsQJBQWYCDYdCFrKF/AelFavHJSXb3PdMRLksYOj5cyz7EMgLDCRbcAAMB4FBYAAGA8CgsAADAehQUAABiPwgIAAIxHYQEAAMajsAAAAONRWAAAgPEoLAAAwHgUFgAAYDwKCwAAMB6FBQAAGI/CAgAAjEdhAQAAxou0OwAAhANHZKNqvHsVERNvd5Q+S3YmKyM+w+4YQJ9QWADgAh1r8yjuoid1385Ou6P0S2xkrLbM20JpQUigsADABTrZ0SRHRKeWT1qtH2RPsjtOnxxoOqCi94vU0N5AYUFIoLAAQICMiBulnNQcu2MAYYmLbgEAgPEoLAAAwHgUFgAAYDwKCwAAMB6FBQAAGI/CAgAAjEdhAQAAxqOwAAAA41FYAACA8RjpFuiHw42n1NDS0eflY441a6yk6i+b1WY1BS/YOdSeaB3wfQJAMFBYgD463HhK+U++p1OdXX1eZ5KjRm85pdtf2609NhSWiJjDisuWEmKjBnzfABBIFBagjxpaOnSqs0slN0zV2LT4Pq0Tc8wlbZKeWThVbcMmBznh2Wq8e3XfTiktwTng+waAQKKwAP00Ni1el4xw9W1hR0+xGTs8Xsrs4zoBFBHTt2IFAKbjolsAAGC8oBSWw4cP62c/+5lSU1MVGxuryZMn6+OPP/bNtyxLq1evVkZGhmJjY5Wfn6/9+/cHIwoAAAgDAS8sDQ0NuvLKKxUVFaX/+q//0qeffqonn3xSycnJvmXWrl2rdevWqaysTJWVlYqLi1NBQYHa2toCHQcAAISBgF/D8thjjykrK0sbN270TcvOzvb927IslZSU6P7779e8efMkSS+99JLS09O1efNmLVy4MNCRAABAiAv4GZY//OEPmj59un784x8rLS1N06ZN0/PPP++bX1NTI4/Ho/z8fN80l8ul3NxcVVRU9LrN9vZ2eb1evxcAABg8Al5YDhw4oA0bNmjcuHF6++23dcstt+i2227Tiy++KEnyeDySpPT0dL/10tPTffO+rri4WC6Xy/fKysoKdGwAAGCwgBeW7u5uXXbZZXrkkUc0bdo0LVu2TEuXLlVZWdl5b7OoqEhNTU2+V21tbQATAwAA0wW8sGRkZCgnJ8dv2sSJE3Xo0CFJktvtliTV1dX5LVNXV+eb93VOp1OJiYl+LwAAMHgEvLBceeWV2rt3r9+0ffv2adSoUZJ6LsB1u90qLy/3zfd6vaqsrFReXl6g4wAAgDAQ8LuE7rjjDl1xxRV65JFH9JOf/EQ7d+7Uc889p+eee06S5HA4tHLlSj300EMaN26csrOztWrVKmVmZur6668PdBwAABAGAl5Yvvvd72rTpk0qKirSmjVrlJ2drZKSEi1atMi3zN13362WlhYtW7ZMjY2Nuuqqq7R161bFxMQEOg4AAAgDQXmW0I9+9CP96Ec/Oud8h8OhNWvWaM2aNcHYPQAACDM8SwgAABiPwgIAAIwXlK+EgKBqrJVajw/4bmOONWuSo0Yxx1ySI75vKx3bF9xQMErtiVZ9crjJ7hh9UuNttjsC0C8UFoSWxlqpdIbU2Trgux4r6S2npE39XDFqqDQ0NQiJYIqE2ChJ0hPb9mltW4vNafomIuaw4rKl+pPtyuHjiRBAYUFoaT3eU1bmPy8Nu3hAd139ZbNuf223nlk4VWOH9/EMi9RTVpJ4nEQ4S0twSpKeuWGqshPH25ymb3Z88RdtqJZOnuq0OwrQJxQWhKZhF0uZUwd0l21Wk/ZYTWobNlnKdA3ovnEOpnzl5v1CknSR44hyHNFnzzewtNZ4h9odAegXCguA0DM0teertjeW2p2kR3SUNCJDeuPnUkcvZyyihkrLdxpXWoBQQmEBEHqSsnoKgA0XX/fK+4VUuUqa/xspcbT/vGP7eopV63EKC3ABKCwAQlNSljkFwPn/vwYafrGUmvPNywI4L4zDAgAAjMcZFgBGOtB0wO4IfRZKWYFQRWEBYJRkZ7JiI2NV9H6R3VH6JTYyVsnOZLtjAGGLwgLAKBnxGdoyb4sa2hvsjtIvyc5kZcRn2B0DCFsUFgDGyYjP4I8/AD9cdAsAAIxHYQEAAMajsAAAAONRWAAAgPEoLAAAwHgUFgAAYDwKCwAAMB6FBQAAGI/CAgAAjEdhAQAAxqOwAAAA41FYAACA8SgsAADAeBQWAABgPAoLAAAwHoUFAAAYj8ICAACMF2l3AAxehxtPqaGlo1/rxBxr1lhJ1V82q81qCk6wc6iubx7Q/QEAvkJhgS0ON55S/pPv6VRnV7/Wm+So0VtO6fbXdmvPABcWSYqNGqLkuOgB3y8ADHYUFtiioaVDpzq7VHLDVI1Ni+/zejHHXNIm6ZmFU9U2bHIQE/YuOS5aI5JiB3y/ADDYUVhgq7Fp8bpkhKvvKzh6ys3Y4fFSZj/WAwCENC66BQAAxqOwAAAA41FYAACA8SgsAADAeBQWAABgPAoLAAAwXtALy6OPPiqHw6GVK1f6prW1tWn58uVKTU1VfHy8FixYoLq6umBHAQAAISqoheWjjz7Sv//7v+vSSy/1m37HHXfoj3/8o37/+9/rvffe05EjRzR//vxgRgEAACEsaIWlublZixYt0vPPP6/k5GTf9KamJv32t7/VU089pR/+8Ie6/PLLtXHjRn3wwQf68MMPgxUHAACEsKAVluXLl2vOnDnKz8/3m15VVaXOzk6/6RMmTNDIkSNVUVHR67ba29vl9Xr9XgAAYPAIytD8r732mnbt2qWPPvrorHkej0fR0dFKSkrym56eni6Px9Pr9oqLi/Xggw8GIyoAAAgBAS8stbW1uv3227Vt2zbFxMQEZJtFRUUqLCz0vfd6vcrKygrItoH+ONp8VA3tDXbH6LMDTQfsjgAAARHwwlJVVaX6+npddtllvmldXV3asWOHnn32Wb399tvq6OhQY2Oj31mWuro6ud3uXrfpdDrldDoDHRXol6PNRzVvyzydOn3K7ij9EhsZq2Rn8rcvCAAGC3hhmTlzpv7nf/7Hb9rNN9+sCRMm6J577lFWVpaioqJUXl6uBQsWSJL27t2rQ4cOKS8vL9BxgIBpaG/QqdOnVPz9Yo1xjbE7Tp8lO5OVEZ9hdwwAuCABLywJCQm65JJL/KbFxcUpNTXVN33JkiUqLCxUSkqKEhMTdeuttyovL0/f+973Ah0HCLgxrjHKSc2xOwYADCpBuej22zz99NOKiIjQggUL1N7eroKCAv3617+2IwoAAAgBA1JY3n33Xb/3MTExKi0tVWlp6UDsHgAAhDieJQQAAIxHYQEAAMajsAAAAONRWAAAgPEoLAAAwHi23NYMAIPOsX12J/AT3Vj91c8j0f4zh6ZKSTz+BGahsABAMA1NlaKGSm8stTuJn6zoKGlEhrLeuU3q6PSfGTVUWr6T0gKjUFgAIJiSsnr++LcetzuJn9qDn0r7ilV7zTrljPo/Izcf29dTrlqPU1hgFAoLAARbUpZxf/w7mjp6fiaNlTKn2hsG6AMuugUAAMajsAAAAONRWAAAgPG4hgW2cUQ2qsa7VxEx8X1fyfuFFB3V89MZ/W1LB9SBpgMDuj8AwFcoLLDFsTaP4i56Uvft7Pz2hb9uRIZUuSrwofogNjJWyc5kW/YNAIMZhQW2ONnRJEdEp5ZPWq0fZE/q+4pf7pPe+Lk0/zfS8IuDF/Ackp3JyojPGPD9AsBgR2GBrUbEjVJOas63L3hGe0fPIFeJo6X+rAcACGlcdAsAAIxHYQEAAMajsAAAAONRWAAAgPG46BYAcLZj++xO0DdDU417ThOCg8ICAPjK0FQpamjPE5tDQdTQnqdhU1rCHoUFAPCVpKyeAtB63O4k3+7Yvp5i1XqcwjIIUFgAAP6SsigAMA4X3QIAAONRWAAAgPEoLAAAwHgUFgAAYDwKCwAAMB6FBQAAGI/CAgAAjMc4LOjRWDugA0VFN1Z/9fNIdN9XDJXhwgEAAUVhQU9ZKZ0hdbYO2C6zoqOkERnKeuc2qaOzfytHDe0ZPhwAMGhQWNBzZqWzVZr/vDTs4gHZZe3BT6V9xaq9Zp1yRuX0b2UedgYAgw6FBV8ZdrGUOXVAdtXR1NHzM2nsgO0TABC6uOgWAAAYj8ICAACMR2EBAADGo7AAAADjUVgAAIDxAl5YiouL9d3vflcJCQlKS0vT9ddfr7179/ot09bWpuXLlys1NVXx8fFasGCB6urqAh0FAACEiYAXlvfee0/Lly/Xhx9+qG3btqmzs1PXXnutWlpafMvccccd+uMf/6jf//73eu+993TkyBHNnz8/0FEAAECYCPg4LFu3bvV7/8ILLygtLU1VVVX6wQ9+oKamJv32t7/VK6+8oh/+8IeSpI0bN2rixIn68MMP9b3vfS/QkQAAQIgL+jUsTU1NkqSUlBRJUlVVlTo7O5Wfn+9bZsKECRo5cqQqKiqCHQcAAISgoI50293drZUrV+rKK6/UJZdcIknyeDyKjo5WUlKS37Lp6enyeDy9bqe9vV3t7e2+916vN2iZAQCAeYJ6hmX58uX65JNP9Nprr13QdoqLi+VyuXyvrCyeIwMAwGAStMKyYsUKvfnmm3rnnXf0ne98xzfd7Xaro6NDjY2NfsvX1dXJ7Xb3uq2ioiI1NTX5XrW1tcGKDQAADBTwwmJZllasWKFNmzZp+/btys7O9pt/+eWXKyoqSuXl5b5pe/fu1aFDh5SXl9frNp1OpxITE/1eAABg8Aj4NSzLly/XK6+8oi1btighIcF3XYrL5VJsbKxcLpeWLFmiwsJCpaSkKDExUbfeeqvy8vK4QwgAAPQq4IVlw4YNkqSrr77ab/rGjRt10003SZKefvppRUREaMGCBWpvb1dBQYF+/etfBzoKAAAIEwEvLJZlfesyMTExKi0tVWlpaaB3DwAAwlBQb2sGAJit9kSrPjncZHeMPkuOi9aIpFi7Y8AGFBYAGIQSYqMkSU9s26e1bS3fsrQ5YqOG6E93/h2lZRCisADAIJSW4JQkPXPDVGUnjrc5Td9U1zdr5eu71dDSQWEZhCgsYeJw4yk1tHSc17oxx5o1VlL1l81qswbm1HDtidYB2Q+Ab3ZRWrxyUl12xwC+FYUlDBxuPKX8J9/Tqc6u81p/kqNGbzml21/brT0DVFgiYg4rLvur09IAAHwTCksYaGjp0KnOLpXcMFVj0+L7vX7MMZe0SXpm4VS1DZschIRnq/Hu1X07vzotDQDAN6GwhJGxafG6ZMR5nNp19JScscPjpcyBOTUcEdP/YgUAGLyC+vBDAACAQOAMCwAgZDgiG1Xj3dtzltb7hRQd1fPTGW13tHNKdiYrIz7D7hghj8ICAAgJx9o8irvoSd23s/OriSMypMpV9oXqg9jIWG2Zt4XScoEoLACAkHCyo0mOiE4tn7RaP8ieJH25T3rj59L830jDL7Y7Xq8ONB1Q0ftFamhvoLBcIAoLACCkjIgbpZzUHKm9Q+rolBJHS6k5dsdCkHHRLQAAMB6FBQAAGI/CAgAAjEdhAQAAxuOiWwAYxA40HbA7Qp8dbjlodwTYiMICAINQsjNZsZGxKnq/yO4o/WJ1RykhmqdLD0YUlmBqrJVajwd9NzHHmjU+6r91+FCTIk4O7f8GGg8O+GiRofT/6oBwlBGfoS3ztqihvcHuKH32eX2zbnt5v4Zd67Y7CmxAYQmWxlqpdIbU2Rr0XcUNGaKGMRn65b4LuCTJhtEiYyNjlexMHtB9AvhKRnxGSA1m1t3WJOv0l3bHgE0oLMHSerynrMx/XhoW3BEY//vgpzq1r1grR96svIwx57eRGJeUkB7YYN+C52sAAPqKwhJswy6WMqcGdRcdTR2SpDT3VcqZMCOo+wIAwA7c1gwAAIxHYQEAAMajsAAAAONRWAAAgPG46BYAEFKq65sl9YxBNVZS9ZfNarOa7A11DjXeZrsjhA0KCwAgJCTHRSs2aohWvr5bkjTJUaO3nNLtr+3WHkMLS0TMYcVlS/Un25WTanea0EZhAQCEhBFJsfrTnX+nhpaeoRxijrmkTdIzC6eqbdhkm9P1bscXf9GGaunkqU67o4Q8CksvjjYfvfDhqr1fDNhw9zwQDMBgMSIpViOSYnveOOIlSWMdR3z/Ns3hiCOSpOjGaqkxQ0rKsjlR6KKwfM3R5qOat2WeTp0+deEbG8Dh7nkgGIBBZ2iqFDVUemOp3UnOKSs6ShqRoax3bpO2R0nLd1JazhOF5Wsa2ht06vQpFX+/WGNc5znMvSR9uU964+fS/N9Iw4M7ND8PBAMwKCVl9RSAAXjI7PmqPfiptK9YddPvUs4Hj/RkpbCcFwrLOYxxjVFOas75b6C9Q+rolBJHSxeynT7ggWAABq2kLKMLwJlHp3QkmJsxVDAOCwAAMB6FBQAAGI/CAgAAjEdhAQAAxuOi23P4vL5Z3W3nP3LiQA4ZfWaYagCAmf63zaNPB2hsrkBJdiYrIz7D7hg+FJavqT/ZLkm6/fXd6m47/ztvBnrI6NioIUqOC43/EQDAYJEQ7ZLVHaWSQxtVMoBjcwVCbGSstszbYkxpobB8zZnhk3/59xfrB6Onnfd2BnrI6OS46K9GfwQAGGFYjFstn9+psjmOnsHjfrhKShpld6xvdaDlsIo+KVNDewOFxXRZKUN1yYgLGDn2zJDRw+OlTEagBYDByjqdpNEp2RpvRUlbV9sdp2/+/wi9OlkX9LHE+srWwlJaWqrHH39cHo9HU6ZM0fr16zVjxgw7IwEAEHCd8SOMH5XXz6H3pL2/kS7gWs5As62wvP766yosLFRZWZlyc3NVUlKigoIC7d27V2lpaXbFAgAg4Krrm6W0REmJdkfpk8PWp3ZHOIttheWpp57S0qVLdfPNN0uSysrK9NZbb+k//uM/dO+999oVCwCAgEmOi1Zs1BCtfH233VH6ZVzMXilbOtHaYXcUH1sKS0dHh6qqqlRUVOSbFhERofz8fFVUVJy1fHt7u9rb233vm5p6TlF5vd6AZ2ttblbXqS61Njdf2PZPNkvtVs/PIOQEAJgvIULatHSaGg36w98Xf/30oJ6p71L9CW9A/9ae2ZZlWf1e15bCcuzYMXV1dSk9Pd1venp6uv72t7+dtXxxcbEefPDBs6ZnZQXvYVILNTMwG3r0+4HZDgAAA2yBlkpaGvDtnjx5Ui5X/25ICYm7hIqKilRYWOh7393drRMnTig1NVUOh8PGZOfm9XqVlZWl2tpaJSaGxneWoYjjPDA4zgOD4zwwOM4D5+vH2rIsnTx5UpmZmf3eli2FZdiwYRoyZIjq6ur8ptfV1cntdp+1vNPplNPp9JuWlJQUzIgBk5iYyP8gBgDHeWBwnAcGx3lgcJwHzv891v09s3KGLc8Sio6O1uWXX67y8nLftO7ubpWXlysvL8+OSAAAwGC2fSVUWFioxYsXa/r06ZoxY4ZKSkrU0tLiu2sIAADgDNsKyw033KAvv/xSq1evlsfj0dSpU7V169azLsQNVU6nUw888MBZX2UhsDjOA4PjPDA4zgOD4zxwAnmsHdb53FsEAAAwgGy5hgUAAKA/KCwAAMB4FBYAAGA8CgsAADAehSUIHn74YV1xxRUaOnToOQe4O3TokObMmaOhQ4cqLS1Nd911l06fPj2wQcPM6NGj5XA4/F6PPvqo3bHCQmlpqUaPHq2YmBjl5uZq586ddkcKK7/61a/O+uxOmDDB7lghb8eOHZo7d64yMzPlcDi0efNmv/mWZWn16tXKyMhQbGys8vPztX//fnvChrBvO8433XTTWZ/vWbNm9Xs/FJYg6Ojo0I9//GPdcsstvc7v6urSnDlz1NHRoQ8++EAvvviiXnjhBa1evXqAk4afNWvW6OjRo77XrbfeanekkPf666+rsLBQDzzwgHbt2qUpU6aooKBA9fX1dkcLK5MmTfL77P75z3+2O1LIa2lp0ZQpU1RaWtrr/LVr12rdunUqKytTZWWl4uLiVFBQoLa2tgFOGtq+7ThL0qxZs/w+36+++mr/d2QhaDZu3Gi5XK6zpv/nf/6nFRERYXk8Ht+0DRs2WImJiVZ7e/sAJgwvo0aNsp5++mm7Y4SdGTNmWMuXL/e97+rqsjIzM63i4mIbU4WXBx54wJoyZYrdMcKaJGvTpk2+993d3Zbb7bYef/xx37TGxkbL6XRar776qg0Jw8PXj7NlWdbixYutefPmXfC2OcNig4qKCk2ePNlvkLyCggJ5vV7t2bPHxmSh79FHH1VqaqqmTZumxx9/nK/ZLlBHR4eqqqqUn5/vmxYREaH8/HxVVFTYmCz87N+/X5mZmRozZowWLVqkQ4cO2R0prNXU1Mjj8fh9tl0ul3Jzc/lsB8G7776rtLQ0jR8/XrfccouOHz/e722ExNOaw43H4zlrRN8z7z0ejx2RwsJtt92myy67TCkpKfrggw9UVFSko0eP6qmnnrI7Wsg6duyYurq6ev28/u1vf7MpVfjJzc3VCy+8oPHjx+vo0aN68MEH9f3vf1+ffPKJEhIS7I4Xls78t7a3zzb/HQ6sWbNmaf78+crOztbnn3+u++67T7Nnz1ZFRYWGDBnS5+1QWPro3nvv1WOPPfaNy3z22WdcKBdg/TnuhYWFvmmXXnqpoqOj9Ytf/ELFxcUMwQ2jzZ492/fvSy+9VLm5uRo1apR+97vfacmSJTYmAy7cwoULff+ePHmyLr30Ul100UV69913NXPmzD5vh8LSR3feeaduuummb1xmzJgxfdqW2+0+6y6Luro63zx85UKOe25urk6fPq0vvvhC48ePD0K68Dds2DANGTLE9/k8o66ujs9qECUlJeniiy9WdXW13VHC1pnPb11dnTIyMnzT6+rqNHXqVJtSDQ5jxozRsGHDVF1dTWEJhuHDh2v48OEB2VZeXp4efvhh1dfXKy0tTZK0bds2JSYmKicnJyD7CBcXctx3796tiIgI3zFG/0VHR+vyyy9XeXm5rr/+eklSd3e3ysvLtWLFCnvDhbHm5mZ9/vnnuvHGG+2OErays7PldrtVXl7uKyher1eVlZXnvMMTgfG///u/On78uF9R7AsKSxAcOnRIJ06c0KFDh9TV1aXdu3dLksaOHav4+Hhde+21ysnJ0Y033qi1a9fK4/Ho/vvv1/Lly/nq4jxVVFSosrJS11xzjRISElRRUaE77rhDP/vZz5ScnGx3vJBWWFioxYsXa/r06ZoxY4ZKSkrU0tKim2++2e5oYeOXv/yl5s6dq1GjRunIkSN64IEHNGTIEP30pz+1O1pIa25u9jtLVVNTo927dyslJUUjR47UypUr9dBDD2ncuHHKzs7WqlWrlJmZ6Svn6JtvOs4pKSl68MEHtWDBArndbn3++ee6++67NXbsWBUUFPRvRxd8nxHOsnjxYkvSWa933nnHt8wXX3xhzZ4924qNjbWGDRtm3XnnnVZnZ6d9oUNcVVWVlZuba7lcLismJsaaOHGi9cgjj1htbW12RwsL69evt0aOHGlFR0dbM2bMsD788EO7I4WVG264wcrIyLCio6OtESNGWDfccINVXV1td6yQ98477/T63+LFixdbltVza/OqVaus9PR0y+l0WjNnzrT27t1rb+gQ9E3HubW11br22mut4cOHW1FRUdaoUaOspUuX+g3r0VcOy7KsC21XAAAAwcQ4LAAAwHgUFgAAYDwKCwAAMB6FBQAAGI/CAgAAjEdhAQAAxqOwAAAA41FYAACA8SgsAADAeBQWAABgPAoLAAAwHoUFAAAY7/8B6qZw2p6ZwxEAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.clf()\n",
    "plt.hist(ret0, histtype=u'step')\n",
    "plt.hist(ret1, histtype=u'step')\n",
    "plt.hist(ret2, histtype=u'step')\n",
    "plt.savefig('updated_cumulative.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
